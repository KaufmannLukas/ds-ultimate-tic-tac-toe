{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "log_ppo_random_v1_1\n",
    "\n",
    "ppo_hyperparameters = {\n",
    "        \"timesteps_per_batch\": 5000,        # timesteps per batch\n",
    "        \"max_timesteps_per_episode\": 1000,  # timesteps per episode\n",
    "        \"gamma\": 0.95,                      # Discount factor to be applied when calculating Rewards-To-Go\n",
    "        \"n_updates_per_iteration\": 10,      # Number of times to update actor/critic per iteration\n",
    "        \"clip\": 0.2,                        # As recommended by the paper\n",
    "        \"lr\": 0.0025,                       # Learning rate of actor optimizer\n",
    "        \"save_freq\": 10,                    # How often we save in number of iterations \n",
    "    }\n",
    "\n",
    "    reward_config = {\n",
    "        \"global_win_factor\": 50,\n",
    "        \"global_draw_factor\": 0,\n",
    "\n",
    "        \"local_win_factor\": 5,\n",
    "        \"local_draw_factor\": 0,\n",
    "\n",
    "        \"legal_move_factor\": 0.1,\n",
    "        \"illegal_move_factor\": -0.2,\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "log_ppo_random_v1_2\n",
    "\n",
    "ppo_hyperparameters = {\n",
    "        \"timesteps_per_batch\": 5000,        # timesteps per batch\n",
    "        \"max_timesteps_per_episode\": 1000,  # timesteps per episode\n",
    "        \"gamma\": 0.95,                      # Discount factor to be applied when calculating Rewards-To-Go\n",
    "        \"n_updates_per_iteration\": 10,      # Number of times to update actor/critic per iteration\n",
    "        \"clip\": 0.2,                        # As recommended by the paper\n",
    "        \"lr\": 0.0025,                       # Learning rate of actor optimizer\n",
    "        \"save_freq\": 10,                    # How often we save in number of iterations \n",
    "    }\n",
    "\n",
    "    reward_config = {\n",
    "        \"global_win_factor\": 50,\n",
    "        \"global_draw_factor\": 0,\n",
    "\n",
    "        \"local_win_factor\": 5,\n",
    "        \"local_draw_factor\": 0,\n",
    "\n",
    "        \"legal_move_factor\": 1,\n",
    "        \"illegal_move_factor\": -5,\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-uttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
