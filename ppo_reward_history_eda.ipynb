{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_rewards = pd.read_csv(\"full_reward_history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>4853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>4854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>4855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>4856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>4857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4858 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    0    1    2    3    4    5    6    7    8  ...  990  991  \\\n",
       "0              0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "1              1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "2              2  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  1.0  1.0   \n",
       "3              3  1.0  1.0  1.0  1.0  3.0  1.0  1.0  1.0  1.0  ...  1.0 -1.0   \n",
       "4              4  1.0  1.0  1.0  1.0  1.0  1.0  1.0  8.0  1.0  ...  1.0 -1.0   \n",
       "...          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "4853        4853  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN   \n",
       "4854        4854  1.0  1.0  1.0  1.0  1.0  1.0  3.0  8.0  1.0  ...  NaN  NaN   \n",
       "4855        4855  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...  NaN  NaN   \n",
       "4856        4856  1.0  1.0  1.0  1.0  1.0  1.0  8.0  3.0  1.0  ...  NaN  NaN   \n",
       "4857        4857  1.0  1.0  1.0  1.0  1.0  1.0  8.0  1.0  1.0  ...  NaN  NaN   \n",
       "\n",
       "      992  993  994  995  996  997  998  999  \n",
       "0     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1     NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2    -1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  \n",
       "3     1.0  1.0  1.0  1.0  1.0  1.0 -1.0  1.0  \n",
       "4     1.0  1.0  1.0  1.0 -1.0  1.0  1.0  1.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "4853  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4854  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4855  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4856  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4857  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[4858 rows x 1001 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.000000\n",
       "1     1.000000\n",
       "2     0.902098\n",
       "3     0.869131\n",
       "4     0.925075\n",
       "5     0.921079\n",
       "6     0.956044\n",
       "7     1.000999\n",
       "8     0.923077\n",
       "9     0.963037\n",
       "10    0.983017\n",
       "11    0.974026\n",
       "12    1.013986\n",
       "13    1.214286\n",
       "14    0.957043\n",
       "15    0.948052\n",
       "16    0.898102\n",
       "17    0.962038\n",
       "18    1.004995\n",
       "19    0.958042\n",
       "20    0.997003\n",
       "21    0.951049\n",
       "22    1.004995\n",
       "23    1.027972\n",
       "24    1.058511\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_rewards.mean(axis=1).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4833     71.914286\n",
       "4834    307.625000\n",
       "4835     81.080645\n",
       "4836    215.000000\n",
       "4837    130.973684\n",
       "4838    235.238095\n",
       "4839     89.267857\n",
       "4840    155.218750\n",
       "4841     68.067568\n",
       "4842    235.095238\n",
       "4843    224.818182\n",
       "4844     62.432099\n",
       "4845    290.647059\n",
       "4846    259.947368\n",
       "4847    290.235294\n",
       "4848    308.500000\n",
       "4849    110.933333\n",
       "4850    124.850000\n",
       "4851     77.261538\n",
       "4852    236.142857\n",
       "4853    275.000000\n",
       "4854    275.055556\n",
       "4855    165.166667\n",
       "4856     49.980583\n",
       "4857     40.706349\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_rewards.mean(axis=1).tail(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23 Nov: 100 games\n",
    "\n",
    "-------------------- Iteration #20 --------------------\n",
    "Average Episodic Length: 25.18\n",
    "Average Episodic Return: 120.8\n",
    "Average Loss: -0.00287\n",
    "Timesteps So Far: 100233\n",
    "Iteration took: 23.72 secs\n",
    "---\n",
    "\n",
    "23 Nov: 100 games\n",
    "\n",
    "-------------------- Iteration #20 --------------------\n",
    "Average Episodic Length: 24.12\n",
    "Average Episodic Return: 117.59\n",
    "Average Loss: -0.003\n",
    "Timesteps So Far: 100299\n",
    "Iteration took: 23.84 secs\n",
    "------------------------------------------------------\n",
    "\n",
    "23 Nov\n",
    "\n",
    "PPO agent v4:\n",
    "- changed layer structure of NN: 3 layers => 4 layers\n",
    "- changed layer structure of bf, wb, bb, lm\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23 Nov\n",
    "\n",
    "\n",
    "# PPO agent v4:\n",
    "# - changed layer structure of NN: 3 layers => 4 layers\n",
    "# - changed layer structure of bf, wb, bb, lm\n",
    "# - \n",
    "\n",
    "# PPO v4\n",
    "# rewards: \n",
    "#   global_wins: 50\n",
    "#   local_wins: 5\n",
    "#   globa_draw: 10\n",
    "#   local_draw: 2\n",
    "#   legal_move: 1\n",
    "#   illegal_move: -1\n",
    "# iterations: 1_000_000\n",
    "# games: 100\n",
    "\n",
    "\n",
    "# 2023-11-23 11:01:28,734 - __main__ - INFO - Start training...\n",
    "# 2023-11-23 11:01:28,734 - gym_envs.uttt_env - INFO - init env\n",
    "# 2023-11-23 11:01:28,734 - agents.ppo - INFO - Init PPO agent...\n",
    "# 2023-11-23 11:01:28,744 - agents.ppo - INFO - start learn with 1000000 total timesteps...\n",
    "# 2023-11-23 11:01:41,656 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:01:41,657 - agents.ppo - INFO - -------------------- Iteration #10 --------------------\n",
    "# 2023-11-23 11:01:41,657 - agents.ppo - INFO - Average Episodic Length: 1000.0\n",
    "# 2023-11-23 11:01:41,657 - agents.ppo - INFO - Average Episodic Return: 463.2\n",
    "# 2023-11-23 11:01:41,657 - agents.ppo - INFO - Average Loss: -0.02128\n",
    "# 2023-11-23 11:01:41,657 - agents.ppo - INFO - Timesteps So Far: 50000\n",
    "# 2023-11-23 11:01:41,657 - agents.ppo - INFO - Iteration took: 12.92 secs\n",
    "# 2023-11-23 11:01:41,657 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:01:55,327 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:01:55,327 - agents.ppo - INFO - -------------------- Iteration #20 --------------------\n",
    "# 2023-11-23 11:01:55,327 - agents.ppo - INFO - Average Episodic Length: 1000.0\n",
    "# 2023-11-23 11:01:55,327 - agents.ppo - INFO - Average Episodic Return: 845.0\n",
    "# 2023-11-23 11:01:55,327 - agents.ppo - INFO - Average Loss: -0.01901\n",
    "# 2023-11-23 11:01:55,327 - agents.ppo - INFO - Timesteps So Far: 100000\n",
    "# 2023-11-23 11:01:55,327 - agents.ppo - INFO - Iteration took: 13.67 secs\n",
    "# 2023-11-23 11:01:55,327 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:02:09,508 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:02:09,508 - agents.ppo - INFO - -------------------- Iteration #30 --------------------\n",
    "# 2023-11-23 11:02:09,508 - agents.ppo - INFO - Average Episodic Length: 1000.0\n",
    "# 2023-11-23 11:02:09,508 - agents.ppo - INFO - Average Episodic Return: 915.6\n",
    "# 2023-11-23 11:02:09,508 - agents.ppo - INFO - Average Loss: -0.01822\n",
    "# 2023-11-23 11:02:09,508 - agents.ppo - INFO - Timesteps So Far: 150000\n",
    "# 2023-11-23 11:02:09,508 - agents.ppo - INFO - Iteration took: 14.18 secs\n",
    "# 2023-11-23 11:02:09,508 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:02:23,736 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:02:23,737 - agents.ppo - INFO - -------------------- Iteration #40 --------------------\n",
    "# 2023-11-23 11:02:23,737 - agents.ppo - INFO - Average Episodic Length: 843.71\n",
    "# 2023-11-23 11:02:23,737 - agents.ppo - INFO - Average Episodic Return: 870.86\n",
    "# 2023-11-23 11:02:23,737 - agents.ppo - INFO - Average Loss: -0.02075\n",
    "# 2023-11-23 11:02:23,737 - agents.ppo - INFO - Timesteps So Far: 201613\n",
    "# 2023-11-23 11:02:23,737 - agents.ppo - INFO - Iteration took: 14.23 secs\n",
    "# 2023-11-23 11:02:23,737 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:02:38,590 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:02:38,591 - agents.ppo - INFO - -------------------- Iteration #50 --------------------\n",
    "# 2023-11-23 11:02:38,591 - agents.ppo - INFO - Average Episodic Length: 856.0\n",
    "# 2023-11-23 11:02:38,591 - agents.ppo - INFO - Average Episodic Return: 1052.83\n",
    "# 2023-11-23 11:02:38,591 - agents.ppo - INFO - Average Loss: -0.02273\n",
    "# 2023-11-23 11:02:38,591 - agents.ppo - INFO - Timesteps So Far: 254114\n",
    "# 2023-11-23 11:02:38,591 - agents.ppo - INFO - Iteration took: 14.85 secs\n",
    "# 2023-11-23 11:02:38,591 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:02:53,579 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:02:53,580 - agents.ppo - INFO - -------------------- Iteration #60 --------------------\n",
    "# 2023-11-23 11:02:53,580 - agents.ppo - INFO - Average Episodic Length: 642.89\n",
    "# 2023-11-23 11:02:53,580 - agents.ppo - INFO - Average Episodic Return: 930.22\n",
    "# 2023-11-23 11:02:53,580 - agents.ppo - INFO - Average Loss: -0.02183\n",
    "# 2023-11-23 11:02:53,580 - agents.ppo - INFO - Timesteps So Far: 307618\n",
    "# 2023-11-23 11:02:53,580 - agents.ppo - INFO - Iteration took: 14.99 secs\n",
    "# 2023-11-23 11:02:53,580 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:03:09,079 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:03:09,080 - agents.ppo - INFO - -------------------- Iteration #70 --------------------\n",
    "# 2023-11-23 11:03:09,080 - agents.ppo - INFO - Average Episodic Length: 527.55\n",
    "# 2023-11-23 11:03:09,080 - agents.ppo - INFO - Average Episodic Return: 894.45\n",
    "# 2023-11-23 11:03:09,080 - agents.ppo - INFO - Average Loss: -0.01854\n",
    "# 2023-11-23 11:03:09,080 - agents.ppo - INFO - Timesteps So Far: 362886\n",
    "# 2023-11-23 11:03:09,080 - agents.ppo - INFO - Iteration took: 15.5 secs\n",
    "# 2023-11-23 11:03:09,080 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:03:24,041 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:03:24,042 - agents.ppo - INFO - -------------------- Iteration #80 --------------------\n",
    "# 2023-11-23 11:03:24,042 - agents.ppo - INFO - Average Episodic Length: 308.22\n",
    "# 2023-11-23 11:03:24,042 - agents.ppo - INFO - Average Episodic Return: 613.28\n",
    "# 2023-11-23 11:03:24,042 - agents.ppo - INFO - Average Loss: -0.01596\n",
    "# 2023-11-23 11:03:24,042 - agents.ppo - INFO - Timesteps So Far: 415890\n",
    "# 2023-11-23 11:03:24,042 - agents.ppo - INFO - Iteration took: 14.96 secs\n",
    "# 2023-11-23 11:03:24,042 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:03:39,042 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:03:39,043 - agents.ppo - INFO - -------------------- Iteration #90 --------------------\n",
    "# 2023-11-23 11:03:39,043 - agents.ppo - INFO - Average Episodic Length: 319.28\n",
    "# 2023-11-23 11:03:39,043 - agents.ppo - INFO - Average Episodic Return: 667.72\n",
    "# 2023-11-23 11:03:39,043 - agents.ppo - INFO - Average Loss: -0.01406\n",
    "# 2023-11-23 11:03:39,043 - agents.ppo - INFO - Timesteps So Far: 468938\n",
    "# 2023-11-23 11:03:39,043 - agents.ppo - INFO - Iteration took: 15.0 secs\n",
    "# 2023-11-23 11:03:39,043 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:03:53,530 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:03:53,531 - agents.ppo - INFO - -------------------- Iteration #100 --------------------\n",
    "# 2023-11-23 11:03:53,531 - agents.ppo - INFO - Average Episodic Length: 138.55\n",
    "# 2023-11-23 11:03:53,531 - agents.ppo - INFO - Average Episodic Return: 330.5\n",
    "# 2023-11-23 11:03:53,531 - agents.ppo - INFO - Average Loss: -0.01356\n",
    "# 2023-11-23 11:03:53,531 - agents.ppo - INFO - Timesteps So Far: 520086\n",
    "# 2023-11-23 11:03:53,531 - agents.ppo - INFO - Iteration took: 14.49 secs\n",
    "# 2023-11-23 11:03:53,531 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:04:08,055 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:04:08,056 - agents.ppo - INFO - -------------------- Iteration #110 --------------------\n",
    "# 2023-11-23 11:04:08,056 - agents.ppo - INFO - Average Episodic Length: 122.54\n",
    "# 2023-11-23 11:04:08,056 - agents.ppo - INFO - Average Episodic Return: 299.9\n",
    "# 2023-11-23 11:04:08,056 - agents.ppo - INFO - Average Loss: -0.01276\n",
    "# 2023-11-23 11:04:08,056 - agents.ppo - INFO - Timesteps So Far: 571036\n",
    "# 2023-11-23 11:04:08,056 - agents.ppo - INFO - Iteration took: 14.52 secs\n",
    "# 2023-11-23 11:04:08,056 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:04:22,578 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:04:22,578 - agents.ppo - INFO - -------------------- Iteration #120 --------------------\n",
    "# 2023-11-23 11:04:22,578 - agents.ppo - INFO - Average Episodic Length: 130.92\n",
    "# 2023-11-23 11:04:22,578 - agents.ppo - INFO - Average Episodic Return: 319.38\n",
    "# 2023-11-23 11:04:22,578 - agents.ppo - INFO - Average Loss: -0.01176\n",
    "# 2023-11-23 11:04:22,578 - agents.ppo - INFO - Timesteps So Far: 621790\n",
    "# 2023-11-23 11:04:22,578 - agents.ppo - INFO - Iteration took: 14.52 secs\n",
    "# 2023-11-23 11:04:22,578 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:04:37,078 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:04:37,079 - agents.ppo - INFO - -------------------- Iteration #130 --------------------\n",
    "# 2023-11-23 11:04:37,079 - agents.ppo - INFO - Average Episodic Length: 78.88\n",
    "# 2023-11-23 11:04:37,079 - agents.ppo - INFO - Average Episodic Return: 212.84\n",
    "# 2023-11-23 11:04:37,079 - agents.ppo - INFO - Average Loss: -0.01153\n",
    "# 2023-11-23 11:04:37,079 - agents.ppo - INFO - Timesteps So Far: 672467\n",
    "# 2023-11-23 11:04:37,079 - agents.ppo - INFO - Iteration took: 14.5 secs\n",
    "# 2023-11-23 11:04:37,079 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:04:51,776 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:04:51,777 - agents.ppo - INFO - -------------------- Iteration #140 --------------------\n",
    "# 2023-11-23 11:04:51,777 - agents.ppo - INFO - Average Episodic Length: 78.84\n",
    "# 2023-11-23 11:04:51,777 - agents.ppo - INFO - Average Episodic Return: 217.05\n",
    "# 2023-11-23 11:04:51,777 - agents.ppo - INFO - Average Loss: -0.01142\n",
    "# 2023-11-23 11:04:51,777 - agents.ppo - INFO - Timesteps So Far: 723326\n",
    "# 2023-11-23 11:04:51,777 - agents.ppo - INFO - Iteration took: 14.7 secs\n",
    "# 2023-11-23 11:04:51,777 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:05:06,348 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:05:06,349 - agents.ppo - INFO - -------------------- Iteration #150 --------------------\n",
    "# 2023-11-23 11:05:06,349 - agents.ppo - INFO - Average Episodic Length: 87.89\n",
    "# 2023-11-23 11:05:06,349 - agents.ppo - INFO - Average Episodic Return: 238.98\n",
    "# 2023-11-23 11:05:06,349 - agents.ppo - INFO - Average Loss: -0.01159\n",
    "# 2023-11-23 11:05:06,349 - agents.ppo - INFO - Timesteps So Far: 773997\n",
    "# 2023-11-23 11:05:06,349 - agents.ppo - INFO - Iteration took: 14.57 secs\n",
    "# 2023-11-23 11:05:06,349 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:05:20,875 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:05:20,876 - agents.ppo - INFO - -------------------- Iteration #160 --------------------\n",
    "# 2023-11-23 11:05:20,876 - agents.ppo - INFO - Average Episodic Length: 71.1\n",
    "# 2023-11-23 11:05:20,876 - agents.ppo - INFO - Average Episodic Return: 203.35\n",
    "# 2023-11-23 11:05:20,876 - agents.ppo - INFO - Average Loss: -0.01122\n",
    "# 2023-11-23 11:05:20,876 - agents.ppo - INFO - Timesteps So Far: 824528\n",
    "# 2023-11-23 11:05:20,876 - agents.ppo - INFO - Iteration took: 14.53 secs\n",
    "# 2023-11-23 11:05:20,876 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:05:35,569 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:05:35,570 - agents.ppo - INFO - -------------------- Iteration #170 --------------------\n",
    "# 2023-11-23 11:05:35,570 - agents.ppo - INFO - Average Episodic Length: 76.45\n",
    "# 2023-11-23 11:05:35,570 - agents.ppo - INFO - Average Episodic Return: 212.77\n",
    "# 2023-11-23 11:05:35,570 - agents.ppo - INFO - Average Loss: -0.01026\n",
    "# 2023-11-23 11:05:35,570 - agents.ppo - INFO - Timesteps So Far: 875075\n",
    "# 2023-11-23 11:05:35,570 - agents.ppo - INFO - Iteration took: 14.69 secs\n",
    "# 2023-11-23 11:05:35,570 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:05:50,297 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:05:50,297 - agents.ppo - INFO - -------------------- Iteration #180 --------------------\n",
    "# 2023-11-23 11:05:50,298 - agents.ppo - INFO - Average Episodic Length: 72.54\n",
    "# 2023-11-23 11:05:50,298 - agents.ppo - INFO - Average Episodic Return: 204.0\n",
    "# 2023-11-23 11:05:50,298 - agents.ppo - INFO - Average Loss: -0.01042\n",
    "# 2023-11-23 11:05:50,298 - agents.ppo - INFO - Timesteps So Far: 925446\n",
    "# 2023-11-23 11:05:50,298 - agents.ppo - INFO - Iteration took: 14.73 secs\n",
    "# 2023-11-23 11:05:50,298 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:06:04,964 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:06:04,965 - agents.ppo - INFO - -------------------- Iteration #190 --------------------\n",
    "# 2023-11-23 11:06:04,965 - agents.ppo - INFO - Average Episodic Length: 62.81\n",
    "# 2023-11-23 11:06:04,966 - agents.ppo - INFO - Average Episodic Return: 190.01\n",
    "# 2023-11-23 11:06:04,966 - agents.ppo - INFO - Average Loss: -0.00984\n",
    "# 2023-11-23 11:06:04,966 - agents.ppo - INFO - Timesteps So Far: 976191\n",
    "# 2023-11-23 11:06:04,966 - agents.ppo - INFO - Iteration took: 14.67 secs\n",
    "# 2023-11-23 11:06:04,966 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:06:12,220 - agents.ppo - INFO - -------------------- Iteration #195 --------------------\n",
    "# 2023-11-23 11:06:12,220 - agents.ppo - INFO - Average Episodic Length: 63.41\n",
    "# 2023-11-23 11:06:12,220 - agents.ppo - INFO - Average Episodic Return: 188.95\n",
    "# 2023-11-23 11:06:12,220 - agents.ppo - INFO - Average Loss: -0.01091\n",
    "# 2023-11-23 11:06:12,220 - agents.ppo - INFO - Timesteps So Far: 1001404\n",
    "# 2023-11-23 11:06:12,220 - agents.ppo - INFO - Iteration took: 7.25 secs\n",
    "# 2023-11-23 11:06:12,220 - agents.ppo - INFO - ------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23 Nov\n",
    "\n",
    "# PPO agent v4:\n",
    "# - changed reward structure\n",
    "# - added batch normalization layers to NN\n",
    "# - \n",
    "\n",
    "# PPO v4\n",
    "# rewards: \n",
    "#   global_wins: 100\n",
    "#   local_wins: 5\n",
    "#   globa_draw: 10\n",
    "#   local_draw: 2\n",
    "#   legal_move: 1\n",
    "#   illegal_move: -2\n",
    "# iterations: 1_000_000\n",
    "# games: 100\n",
    "\n",
    "\n",
    "# 2023-11-23 11:23:28,218 - __main__ - INFO - Start training...\n",
    "# 2023-11-23 11:23:28,219 - gym_envs.uttt_env - INFO - init env\n",
    "# 2023-11-23 11:23:28,219 - agents.ppo - INFO - Init PPO agent...\n",
    "# 2023-11-23 11:23:28,222 - agents.ppo - INFO - start learn with 1000000 total timesteps...\n",
    "# 2023-11-23 11:23:41,135 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:23:41,136 - agents.ppo - INFO - -------------------- Iteration #10 --------------------\n",
    "# 2023-11-23 11:23:41,136 - agents.ppo - INFO - Average Episodic Length: 1000.0\n",
    "# 2023-11-23 11:23:41,136 - agents.ppo - INFO - Average Episodic Return: -170.6\n",
    "# 2023-11-23 11:23:41,136 - agents.ppo - INFO - Average Loss: -0.0157\n",
    "# 2023-11-23 11:23:41,136 - agents.ppo - INFO - Timesteps So Far: 50000\n",
    "# 2023-11-23 11:23:41,136 - agents.ppo - INFO - Iteration took: 12.92 secs\n",
    "# 2023-11-23 11:23:41,136 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:23:54,585 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:23:54,586 - agents.ppo - INFO - -------------------- Iteration #20 --------------------\n",
    "# 2023-11-23 11:23:54,586 - agents.ppo - INFO - Average Episodic Length: 1000.0\n",
    "# 2023-11-23 11:23:54,586 - agents.ppo - INFO - Average Episodic Return: 647.2\n",
    "# 2023-11-23 11:23:54,586 - agents.ppo - INFO - Average Loss: -0.02388\n",
    "# 2023-11-23 11:23:54,586 - agents.ppo - INFO - Timesteps So Far: 100000\n",
    "# 2023-11-23 11:23:54,586 - agents.ppo - INFO - Iteration took: 13.45 secs\n",
    "# 2023-11-23 11:23:54,586 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:24:08,481 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:24:08,482 - agents.ppo - INFO - -------------------- Iteration #30 --------------------\n",
    "# 2023-11-23 11:24:08,482 - agents.ppo - INFO - Average Episodic Length: 1000.0\n",
    "# 2023-11-23 11:24:08,482 - agents.ppo - INFO - Average Episodic Return: 766.6\n",
    "# 2023-11-23 11:24:08,482 - agents.ppo - INFO - Average Loss: -0.01922\n",
    "# 2023-11-23 11:24:08,482 - agents.ppo - INFO - Timesteps So Far: 150000\n",
    "# 2023-11-23 11:24:08,482 - agents.ppo - INFO - Iteration took: 13.9 secs\n",
    "# 2023-11-23 11:24:08,482 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:24:22,257 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:24:22,258 - agents.ppo - INFO - -------------------- Iteration #40 --------------------\n",
    "# 2023-11-23 11:24:22,258 - agents.ppo - INFO - Average Episodic Length: 1000.0\n",
    "# 2023-11-23 11:24:22,258 - agents.ppo - INFO - Average Episodic Return: 901.6\n",
    "# 2023-11-23 11:24:22,258 - agents.ppo - INFO - Average Loss: -0.02243\n",
    "# 2023-11-23 11:24:22,258 - agents.ppo - INFO - Timesteps So Far: 200000\n",
    "# 2023-11-23 11:24:22,258 - agents.ppo - INFO - Iteration took: 13.78 secs\n",
    "# 2023-11-23 11:24:22,258 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:24:36,761 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:24:36,762 - agents.ppo - INFO - -------------------- Iteration #50 --------------------\n",
    "# 2023-11-23 11:24:36,762 - agents.ppo - INFO - Average Episodic Length: 712.88\n",
    "# 2023-11-23 11:24:36,762 - agents.ppo - INFO - Average Episodic Return: 808.0\n",
    "# 2023-11-23 11:24:36,762 - agents.ppo - INFO - Average Loss: -0.02416\n",
    "# 2023-11-23 11:24:36,762 - agents.ppo - INFO - Timesteps So Far: 251793\n",
    "# 2023-11-23 11:24:36,762 - agents.ppo - INFO - Iteration took: 14.5 secs\n",
    "# 2023-11-23 11:24:36,762 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:24:52,388 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:24:52,389 - agents.ppo - INFO - -------------------- Iteration #60 --------------------\n",
    "# 2023-11-23 11:24:52,389 - agents.ppo - INFO - Average Episodic Length: 867.83\n",
    "# 2023-11-23 11:24:52,389 - agents.ppo - INFO - Average Episodic Return: 1144.67\n",
    "# 2023-11-23 11:24:52,389 - agents.ppo - INFO - Average Loss: -0.02131\n",
    "# 2023-11-23 11:24:52,390 - agents.ppo - INFO - Timesteps So Far: 305852\n",
    "# 2023-11-23 11:24:52,390 - agents.ppo - INFO - Iteration took: 15.63 secs\n",
    "# 2023-11-23 11:24:52,390 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:25:08,683 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:25:08,683 - agents.ppo - INFO - -------------------- Iteration #70 --------------------\n",
    "# 2023-11-23 11:25:08,683 - agents.ppo - INFO - Average Episodic Length: 778.43\n",
    "# 2023-11-23 11:25:08,683 - agents.ppo - INFO - Average Episodic Return: 1103.14\n",
    "# 2023-11-23 11:25:08,683 - agents.ppo - INFO - Average Loss: -0.01908\n",
    "# 2023-11-23 11:25:08,684 - agents.ppo - INFO - Timesteps So Far: 361053\n",
    "# 2023-11-23 11:25:08,684 - agents.ppo - INFO - Iteration took: 16.29 secs\n",
    "# 2023-11-23 11:25:08,684 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:25:23,756 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:25:23,757 - agents.ppo - INFO - -------------------- Iteration #80 --------------------\n",
    "# 2023-11-23 11:25:23,757 - agents.ppo - INFO - Average Episodic Length: 379.36\n",
    "# 2023-11-23 11:25:23,757 - agents.ppo - INFO - Average Episodic Return: 674.36\n",
    "# 2023-11-23 11:25:23,757 - agents.ppo - INFO - Average Loss: -0.01839\n",
    "# 2023-11-23 11:25:23,757 - agents.ppo - INFO - Timesteps So Far: 414054\n",
    "# 2023-11-23 11:25:23,757 - agents.ppo - INFO - Iteration took: 15.07 secs\n",
    "# 2023-11-23 11:25:23,757 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:25:38,530 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:25:38,531 - agents.ppo - INFO - -------------------- Iteration #90 --------------------\n",
    "# 2023-11-23 11:25:38,531 - agents.ppo - INFO - Average Episodic Length: 180.36\n",
    "# 2023-11-23 11:25:38,531 - agents.ppo - INFO - Average Episodic Return: 389.25\n",
    "# 2023-11-23 11:25:38,531 - agents.ppo - INFO - Average Loss: -0.01749\n",
    "# 2023-11-23 11:25:38,531 - agents.ppo - INFO - Timesteps So Far: 465781\n",
    "# 2023-11-23 11:25:38,531 - agents.ppo - INFO - Iteration took: 14.77 secs\n",
    "# 2023-11-23 11:25:38,531 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:25:53,080 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:25:53,080 - agents.ppo - INFO - -------------------- Iteration #100 --------------------\n",
    "# 2023-11-23 11:25:53,080 - agents.ppo - INFO - Average Episodic Length: 122.52\n",
    "# 2023-11-23 11:25:53,080 - agents.ppo - INFO - Average Episodic Return: 311.93\n",
    "# 2023-11-23 11:25:53,080 - agents.ppo - INFO - Average Loss: -0.01576\n",
    "# 2023-11-23 11:25:53,080 - agents.ppo - INFO - Timesteps So Far: 516678\n",
    "# 2023-11-23 11:25:53,080 - agents.ppo - INFO - Iteration took: 14.55 secs\n",
    "# 2023-11-23 11:25:53,080 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:26:07,681 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:26:07,682 - agents.ppo - INFO - -------------------- Iteration #110 --------------------\n",
    "# 2023-11-23 11:26:07,682 - agents.ppo - INFO - Average Episodic Length: 110.74\n",
    "# 2023-11-23 11:26:07,682 - agents.ppo - INFO - Average Episodic Return: 290.24\n",
    "# 2023-11-23 11:26:07,682 - agents.ppo - INFO - Average Loss: -0.01501\n",
    "# 2023-11-23 11:26:07,682 - agents.ppo - INFO - Timesteps So Far: 567772\n",
    "# 2023-11-23 11:26:07,682 - agents.ppo - INFO - Iteration took: 14.6 secs\n",
    "# 2023-11-23 11:26:07,682 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:26:22,196 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:26:22,197 - agents.ppo - INFO - -------------------- Iteration #120 --------------------\n",
    "# 2023-11-23 11:26:22,197 - agents.ppo - INFO - Average Episodic Length: 71.59\n",
    "# 2023-11-23 11:26:22,197 - agents.ppo - INFO - Average Episodic Return: 231.9\n",
    "# 2023-11-23 11:26:22,197 - agents.ppo - INFO - Average Loss: -0.01404\n",
    "# 2023-11-23 11:26:22,197 - agents.ppo - INFO - Timesteps So Far: 618403\n",
    "# 2023-11-23 11:26:22,197 - agents.ppo - INFO - Iteration took: 14.51 secs\n",
    "# 2023-11-23 11:26:22,197 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:26:36,734 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:26:36,735 - agents.ppo - INFO - -------------------- Iteration #130 --------------------\n",
    "# 2023-11-23 11:26:36,735 - agents.ppo - INFO - Average Episodic Length: 57.9\n",
    "# 2023-11-23 11:26:36,735 - agents.ppo - INFO - Average Episodic Return: 210.09\n",
    "# 2023-11-23 11:26:36,735 - agents.ppo - INFO - Average Loss: -0.01338\n",
    "# 2023-11-23 11:26:36,735 - agents.ppo - INFO - Timesteps So Far: 668858\n",
    "# 2023-11-23 11:26:36,735 - agents.ppo - INFO - Iteration took: 14.54 secs\n",
    "# 2023-11-23 11:26:36,735 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:26:51,191 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:26:51,192 - agents.ppo - INFO - -------------------- Iteration #140 --------------------\n",
    "# 2023-11-23 11:26:51,192 - agents.ppo - INFO - Average Episodic Length: 48.75\n",
    "# 2023-11-23 11:26:51,192 - agents.ppo - INFO - Average Episodic Return: 193.48\n",
    "# 2023-11-23 11:26:51,192 - agents.ppo - INFO - Average Loss: -0.01318\n",
    "# 2023-11-23 11:26:51,192 - agents.ppo - INFO - Timesteps So Far: 719350\n",
    "# 2023-11-23 11:26:51,192 - agents.ppo - INFO - Iteration took: 14.46 secs\n",
    "# 2023-11-23 11:26:51,192 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:27:05,453 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:27:05,454 - agents.ppo - INFO - -------------------- Iteration #150 --------------------\n",
    "# 2023-11-23 11:27:05,454 - agents.ppo - INFO - Average Episodic Length: 42.38\n",
    "# 2023-11-23 11:27:05,454 - agents.ppo - INFO - Average Episodic Return: 185.03\n",
    "# 2023-11-23 11:27:05,454 - agents.ppo - INFO - Average Loss: -0.01338\n",
    "# 2023-11-23 11:27:05,454 - agents.ppo - INFO - Timesteps So Far: 769696\n",
    "# 2023-11-23 11:27:05,454 - agents.ppo - INFO - Iteration took: 14.26 secs\n",
    "# 2023-11-23 11:27:05,454 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:27:19,782 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:27:19,783 - agents.ppo - INFO - -------------------- Iteration #160 --------------------\n",
    "# 2023-11-23 11:27:19,783 - agents.ppo - INFO - Average Episodic Length: 40.44\n",
    "# 2023-11-23 11:27:19,783 - agents.ppo - INFO - Average Episodic Return: 184.1\n",
    "# 2023-11-23 11:27:19,783 - agents.ppo - INFO - Average Loss: -0.01278\n",
    "# 2023-11-23 11:27:19,783 - agents.ppo - INFO - Timesteps So Far: 819895\n",
    "# 2023-11-23 11:27:19,783 - agents.ppo - INFO - Iteration took: 14.33 secs\n",
    "# 2023-11-23 11:27:19,783 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:27:34,056 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:27:34,057 - agents.ppo - INFO - -------------------- Iteration #170 --------------------\n",
    "# 2023-11-23 11:27:34,057 - agents.ppo - INFO - Average Episodic Length: 39.1\n",
    "# 2023-11-23 11:27:34,058 - agents.ppo - INFO - Average Episodic Return: 182.69\n",
    "# 2023-11-23 11:27:34,058 - agents.ppo - INFO - Average Loss: -0.01259\n",
    "# 2023-11-23 11:27:34,058 - agents.ppo - INFO - Timesteps So Far: 870104\n",
    "# 2023-11-23 11:27:34,058 - agents.ppo - INFO - Iteration took: 14.27 secs\n",
    "# 2023-11-23 11:27:34,058 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:27:48,810 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:27:48,811 - agents.ppo - INFO - -------------------- Iteration #180 --------------------\n",
    "# 2023-11-23 11:27:48,811 - agents.ppo - INFO - Average Episodic Length: 37.57\n",
    "# 2023-11-23 11:27:48,811 - agents.ppo - INFO - Average Episodic Return: 179.35\n",
    "# 2023-11-23 11:27:48,811 - agents.ppo - INFO - Average Loss: -0.01182\n",
    "# 2023-11-23 11:27:48,811 - agents.ppo - INFO - Timesteps So Far: 920315\n",
    "# 2023-11-23 11:27:48,811 - agents.ppo - INFO - Iteration took: 14.75 secs\n",
    "# 2023-11-23 11:27:48,811 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:28:03,283 - agents.ppo - INFO - saved files\n",
    "# 2023-11-23 11:28:03,284 - agents.ppo - INFO - -------------------- Iteration #190 --------------------\n",
    "# 2023-11-23 11:28:03,284 - agents.ppo - INFO - Average Episodic Length: 35.02\n",
    "# 2023-11-23 11:28:03,284 - agents.ppo - INFO - Average Episodic Return: 172.01\n",
    "# 2023-11-23 11:28:03,284 - agents.ppo - INFO - Average Loss: -0.01228\n",
    "# 2023-11-23 11:28:03,284 - agents.ppo - INFO - Timesteps So Far: 970640\n",
    "# 2023-11-23 11:28:03,284 - agents.ppo - INFO - Iteration took: 14.47 secs\n",
    "# 2023-11-23 11:28:03,284 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:28:11,832 - agents.ppo - INFO - -------------------- Iteration #196 --------------------\n",
    "# 2023-11-23 11:28:11,832 - agents.ppo - INFO - Average Episodic Length: 33.21\n",
    "# 2023-11-23 11:28:11,832 - agents.ppo - INFO - Average Episodic Return: 168.01\n",
    "# 2023-11-23 11:28:11,832 - agents.ppo - INFO - Average Loss: -0.01234\n",
    "# 2023-11-23 11:28:11,832 - agents.ppo - INFO - Timesteps So Far: 1000777\n",
    "# 2023-11-23 11:28:11,832 - agents.ppo - INFO - Iteration took: 8.55 secs\n",
    "# 2023-11-23 11:28:11,832 - agents.ppo - INFO - ------------------------------------------------------\n",
    "# 2023-11-23 11:28:13,761 - __main__ - INFO - End training..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-uttt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
